{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76bc3f6a",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of states\n",
    "states = ['bihar', 'delhi', 'haryana', 'maharashtra', 'punjab', 'telangana', 'up', 'bengal']\n",
    "language_code = 'en'\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Read and concatenate data for all states\n",
    "for state in states:\n",
    "    file_path = f\"responses/llama_responses/most_frequent_answers_{state}_{language_code}.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        state_df = pd.read_csv(file_path)\n",
    "        state_df['State'] = state  # Add a column for the state\n",
    "        combined_df = pd.concat([combined_df, state_df], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(f\"responses/llama_responses/most_frequent_answers_allstates_india_{language_code}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb1378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching questions: 91\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load input files\n",
    "with open('data/chosen_cols.json', 'r') as f:\n",
    "    chosen_cols = json.load(f)\n",
    "\n",
    "with open('data/qsns_mapping.json', 'r') as f:\n",
    "    qsns_mapping = json.load(f)\n",
    "\n",
    "with open('data/questions.json', 'r') as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "# Compute the list of true_qsns\n",
    "true_qsns = [\n",
    "    qsn for qsn, val in chosen_cols['chosen_cols'].items()\n",
    "    if val \n",
    "    and qsn in qsns_mapping['2012'].values() \n",
    "    and qsn in qsns_mapping['2006'].values() \n",
    "    and qsn in questions\n",
    "]\n",
    "\n",
    "print(f\"Number of matching questions: {len(true_qsns)}\")\n",
    "\n",
    "with open('data/chosen_cols_updated.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "for key in data['chosen_cols']:\n",
    "    if key in true_qsns:\n",
    "        data['chosen_cols'][key] = True\n",
    "    else:\n",
    "        data['chosen_cols'][key] = False\n",
    "\n",
    "with open('data/chosen_cols_updated.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df084436",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_questions_only_text = {qsn: questions[qsn] for qsn in true_qsns}\n",
    "with open('data/selected_questions_only.json', 'w') as f:\n",
    "    json.dump(selected_questions_only_text, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d52cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOCIAL VALUES, ATTITUDES & STEREOTYPES: 24 question(s)\n",
      "SOCIAL CAPITAL, TRUST & ORGANIZATIONAL MEMBERSHIP: 23 question(s)\n",
      "ECONOMIC VALUES: 6 question(s)\n",
      "SECURITY: 1 question(s)\n",
      "POSTMATERIALIST INDEX: 6 question(s)\n",
      "SCIENCE & TECHNOLOGY: 4 question(s)\n",
      "RELIGIOUS VALUES: 1 question(s)\n",
      "ETHICAL VALUES AND NORMS: 11 question(s)\n",
      "POLITICAL CULTURE & POLITICAL REGIMES: 15 question(s)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "with open('data/themes.json', 'r') as f:\n",
    "    themes = json.load(f)\n",
    "\n",
    "# Prepare ranges as tuples (start, end) for easier comparison\n",
    "theme_ranges = {}\n",
    "for key, theme_name in themes.items():\n",
    "    start, end = map(int, key.split('-'))\n",
    "    theme_ranges[(start, end)] = theme_name\n",
    "\n",
    "# Count questions per theme\n",
    "theme_counts = defaultdict(int)\n",
    "\n",
    "for q in true_qsns:\n",
    "    # Extract question number as integer\n",
    "    q_num = int(q[1:]) \n",
    "    for (start, end), theme_name in theme_ranges.items():\n",
    "        if start <= q_num <= end:\n",
    "            theme_counts[theme_name] += 1\n",
    "            break \n",
    "\n",
    "# Display results\n",
    "for theme, count in theme_counts.items():\n",
    "    print(f\"{theme}: {count} question(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad918d",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bec9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2022'\n",
    "country = 'india'\n",
    "language_code = 'en'\n",
    "filename = '{year}_{country}'.format(year=year, country=country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b683fe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayita/Documents/Projects/NLP_Projects/Ethics/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1810, Columns: 396\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(f\"data/{country}/{year}/{filename}.xlsx\")\n",
    "\n",
    "rows, cols = df.shape\n",
    "print(f\"Rows: {rows}, Columns: {cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d99fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/chosen_cols_updated.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    chosen_cols = [colname for colname in data[\"chosen_cols\"] if data[\"chosen_cols\"][colname] is True]\n",
    "    persona_cols = data[\"persona_cols\"][year].get(country, data[\"persona_cols\"][year]['all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3126b61e",
   "metadata": {},
   "source": [
    "## Chosen Persona Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f83e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_persona_cols = list(persona_cols.values())\n",
    "grouped = df[all_persona_cols].groupby(all_persona_cols).size().reset_index(name='Counts')\n",
    "grouped.to_csv(f\"data/{country}/{year}/{filename}_persona_groups_{language_code}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ec70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_cleaned = grouped[grouped[\"Counts\"] >= 4]\n",
    "grouped_cleaned.to_csv(f\"data/{country}/{year}/{filename}_persona_groups_cleaned_{language_code}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367dd59",
   "metadata": {},
   "source": [
    "## Persona Majority Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed276f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_majority_answers(year='2022', country='india', language_code='en'):\n",
    "    persona_filepath = f\"data/{country}/{year}/{year}_{country}_persona_groups_cleaned_{language_code}.csv\"\n",
    "    raw_data_filepath = f\"data/{country}/{year}/{year}_{country}.xlsx\"\n",
    "    output_filepath = f\"data/{country}/{year}/{year}_{country}_majority_answers_by_persona_{language_code}.csv\"\n",
    "\n",
    "    personas_df = pd.read_csv(persona_filepath)\n",
    "    raw_data_df = pd.read_excel(raw_data_filepath)\n",
    "\n",
    "    # Identify the demographic columns to group by\n",
    "    demographic_columns = personas_df.columns.drop('Counts').tolist()\n",
    "\n",
    "    # Identify question columns (contain ':' but are not demographics)\n",
    "    question_columns = [col for col in raw_data_df.columns if ':' in col and col not in demographic_columns]\n",
    "\n",
    "    print(f\"Grouping by {len(demographic_columns)} demographic columns.\")\n",
    "    print(f\"Analyzing {len(question_columns)} question columns.\")\n",
    "\n",
    "    # Ensure both DataFrames have consistent types for grouping columns\n",
    "    for col in demographic_columns:\n",
    "        personas_df[col] = personas_df[col].astype(str)\n",
    "        raw_data_df[col] = raw_data_df[col].astype(str)\n",
    "\n",
    "    # Function to compute majority value (mode)\n",
    "    def get_majority(series):\n",
    "        modes = series.mode()\n",
    "        return modes[0] if not modes.empty else np.nan\n",
    "\n",
    "    # Create aggregation mapping\n",
    "    agg_dict = {col: get_majority for col in question_columns}\n",
    "\n",
    "    # Replace values\n",
    "    print(\"Calculating majority answers for each persona group...\")\n",
    "    majority_answers_df = raw_data_df.groupby(demographic_columns).agg(agg_dict).reset_index()\n",
    "\n",
    "    # Merge results\n",
    "    final_df = pd.merge(personas_df, majority_answers_df, on=demographic_columns, how='left')\n",
    "    \n",
    "    for col in question_columns:\n",
    "        final_df[col] = final_df[col].astype(str).apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "    # Save final result\n",
    "    final_df.to_csv(output_filepath, index=False)\n",
    "    print(f\"\\nSuccessfully created output file at: {output_filepath}\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1ea5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing country: india, language: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayita/Documents/Projects/NLP_Projects/Ethics/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping by 10 demographic columns.\n",
      "Analyzing 445 question columns.\n",
      "Calculating majority answers for each persona group...\n",
      "\n",
      "Successfully created output file at: data/india/2022/2022_india_majority_answers_by_persona_en.csv\n",
      "\n",
      "Processing country: US, language: ru\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/US/2022/2022_US_persona_groups_cleaned_ru.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m country, language_code \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(countries, language_codes):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessing country: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, language: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mcalculate_majority_answers\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m=\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcountry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcountry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcalculate_majority_answers\u001b[39m\u001b[34m(year, country, language_code)\u001b[39m\n\u001b[32m      6\u001b[39m raw_data_filepath = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m output_filepath = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_majority_answers_by_persona_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m personas_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersona_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m raw_data_df = pd.read_excel(raw_data_filepath)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Identify the demographic columns to group by\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/NLP_Projects/Ethics/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/NLP_Projects/Ethics/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/NLP_Projects/Ethics/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/NLP_Projects/Ethics/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/NLP_Projects/Ethics/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/US/2022/2022_US_persona_groups_cleaned_ru.csv'"
     ]
    }
   ],
   "source": [
    "year = '2022'\n",
    "countries = ['india', 'US', 'russia', 'japan', 'colombia', 'egypt']\n",
    "language_codes = ['en', 'ru', 'hi', 'ja', 'sp', 'ar']\n",
    "\n",
    "for country, language_code in zip(countries, language_codes):\n",
    "    print(f\"\\nProcessing country: {country}, language: {language_code}\")\n",
    "    calculate_majority_answers(year=year, country=country, language_code=language_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e746f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayita/Documents/Projects/NLP_Projects/Ethics/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping by 10 demographic columns.\n",
      "Analyzing 386 question columns.\n",
      "Calculating majority answers for each persona group...\n",
      "\n",
      "Successfully created output file at: data/russia/2022/2022_russia_majority_answers_by_persona_en.csv\n"
     ]
    }
   ],
   "source": [
    "result_df = calculate_majority_answers(year=year, country=country, language_code=language_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537865b",
   "metadata": {},
   "source": [
    "## Chosen Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2500, Columns: 10\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "def is_chosen_col(col):\n",
    "    qsn = col.split(':')[0].strip()\n",
    "    return qsn in chosen_cols\n",
    "\n",
    "chosen_col_names = list(persona_cols.values()) + [col for col in df.columns if is_chosen_col(col)]\n",
    "chosen = df[chosen_col_names]\n",
    "chosen.to_csv(f\"data/{country}/{year}/{filename}_cleaned_{language_code}.csv\", index=False)\n",
    "\n",
    "rows, cols = chosen.shape\n",
    "print(f\"Rows: {rows}, Columns: {cols}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
